simulator_name: mobl_arms_index_choice_reaction_hit_bonus_dist_dc_effort_w1

simulation:
  bm_model:
    cls: MoblArmsIndexDistanceSensor
    kwargs:
      shoulder_variant: none
      effort_model:
        cls: DC
        kwargs:
          r1: 0.001477
  task:
    cls: ChoiceReaction_distance_sensor_force_constraint
    kwargs:
      end_effector: [geom, hand_2distph]
      shoulder: [body, humphant]
      reward_function: DistanceWithHitBonus
  perception_modules:
  - cls: vision.FixedEye
    kwargs:
      resolution: [120, 80]
      channels: [0, 1, 2, 3]
      pos: 0 0 1.2
      quat: 0.583833 0.399104 -0.399421 -0.583368
  - cls: proprioception.BasicWithEndEffectorPosition
    kwargs:
      end_effector: [geom, hand_2distph]
  run_parameters:
    action_sample_freq: 20
    random_seed: 100
    info_keywords: [[success_rate_button-0, final], [success_rate_button-1, final],
      [success_rate_button-2, final], [success_rate_button-3, final]]
rl:
  algorithm: PPO
  policy_type: policies.MultiInputActorCriticPolicyTanhActions
  policy_kwargs:
    activation_fn: torch.nn.LeakyReLU
    net_arch: [256, 256]
    log_std_init: 0.0
    features_extractor_class: feature_extractor.FeatureExtractor
    normalize_images: false
  lr:
    function: schedule.linear_schedule
    kwargs:
      initial_value: 5e-5
      min_value: 1e-7
      threshold: 0.8
  total_timesteps: 35_000_000
  device: cuda
  num_workers: 10
  nsteps: 4000
  batch_size: 500
  target_kl: 1.0
  save_freq: 5_000_000
version: 1.1.0
package_name: mobl_arms_index_choice_reaction_hit_bonus_dist_dc_effort_w1
gym_name: uitb:mobl_arms_index_choice_reaction_hit_bonus_dist_dc_effort_w1-v0
built: '2025-01-18 00:53:07'
